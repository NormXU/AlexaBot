{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[141  54  27  27]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'count_eye' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-63fe992aaad6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;31m#           ex_smallest = np.minimum(ex)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;31m#           index_smallest = where(ex==ex_smallest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mcount_eye\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_eye\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcount_eye\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_eye' is not defined"
     ]
    }
   ],
   "source": [
    "# eyeball and iris tracking (old way)\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def sequential_label(binary_in):\n",
    "    a = binary_in.shape\n",
    "    a = np.array([int(v) for v in a])\n",
    "    I = binary_in\n",
    "    label = 0\n",
    "    labeled_image = np.zeros((a[0],a[1]))\n",
    "    record = []\n",
    "    for i in range(1,a[0]):\n",
    "        for j in range(1,a[1]):\n",
    "            if I[i][j]!=0: \n",
    "                if labeled_image[i-1][j-1]!=0:\n",
    "                    labeled_image[i][j] = labeled_image[i-1][j-1]\n",
    "\n",
    "                elif labeled_image[i][j-1]==0 and labeled_image[i-1][j]==0:\n",
    "                    label = label+1\n",
    "                    labeled_image[i][j] = label\n",
    "                elif labeled_image[i-1][j]!=0 and labeled_image[i][j-1]==0:\n",
    "                    labeled_image[i][j] = labeled_image[i-1][j]\n",
    "\n",
    "                elif labeled_image[i-1][j]==0 and labeled_image[i][j-1]!=0:\n",
    "                    labeled_image[i][j] = labeled_image[i][j-1]    \n",
    "\n",
    "                elif labeled_image[i-1][j]!=0 and labeled_image[i][j-1]!=0:\n",
    "\n",
    "                    if labeled_image[i][j-1]==labeled_image[i-1][j]:\n",
    "                        labeled_image[i][j] = labeled_image[i][j-1]\n",
    "\n",
    "                    else: \n",
    "                        minValue = min(labeled_image[i][j-1],labeled_image[i-1][j])\n",
    "                        maxValue = max(labeled_image[i][j-1],labeled_image[i-1][j])\n",
    "                        labeled_image[i][j] = labeled_image[i][j-1]\n",
    "                        # record equivalence of labels\n",
    "                        labeled_image = np.where(labeled_image == minValue, maxValue, labeled_image)\n",
    "\n",
    "    labelled_img = labeled_image\n",
    "    # normalized\n",
    "    \n",
    "    max_labelled_img = labelled_img.max()\n",
    "    labelled_img = (labelled_img*(255/max_labelled_img)).astype('uint8')\n",
    "    \n",
    "        \n",
    "    return labelled_img\n",
    "\n",
    "def moment_opencv(labelled_in):\n",
    "    res = {}\n",
    "    for label_idx in np.unique(labelled_in):\n",
    "        if label_idx == 0:\n",
    "            continue\n",
    "        masked_in = (labelled_in==label_idx).astype(labelled_in.dtype)\n",
    "        moments = cv2.moments(masked_in)\n",
    "        res[label_idx] = [moments['m00'],moments['m01'],moments['m10'],\n",
    "                          moments['m02'],moments['m11'],moments['m20'],\n",
    "                          moments['mu02'],moments['mu11'],moments['mu20']]\n",
    "    return res\n",
    "\n",
    "def binarize(gray_in, threshold=128):\n",
    "    #ret,thresh1 = cv2.threshold(img,threshold,255,cv.THRESH_BINARY)\n",
    "    binary_image = np.where(gray_in>threshold,0,255).astype('uint8')\n",
    "    return binary_image\n",
    "\n",
    "def find_iris(eye_image):\n",
    "    eye = np.array(eye_image)\n",
    "    gray_eye = np.array(eye)\n",
    "    [H,L] = eye_image.shape    \n",
    "    scaler_x= H/40.\n",
    "    scaler_y=L/40.\n",
    "    gray_eye = cv2.resize(gray_eye,(40,40))\n",
    "    #cv2.imshow('frame2',gray_eye)\n",
    "\n",
    "    print (scaler_x,scaler_y)\n",
    "    gray_eye = cv2.medianBlur(gray_eye, 5)\n",
    "    gray_eye = binarize(gray_eye,50)\n",
    "    label = sequential_label(gray_eye)\n",
    "    cv2.imshow('frame3',label)\n",
    "    if label.max() == 0:\n",
    "        x_hat = 0\n",
    "        y_hat = 0\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        res = moment_opencv(label)\n",
    "        list_A = []\n",
    "        list_i = []\n",
    "        count = 0\n",
    "        for i in res:\n",
    "            list_A.append(res[i][0])\n",
    "            count = count+1\n",
    "            list_i.append(i)\n",
    "        index = np.where(list_A == max(list_A))\n",
    "                \n",
    "        index = np.array(index)       \n",
    "        \n",
    "    \n",
    "        if index.shape == (1,0):\n",
    "            index = 0\n",
    "            \n",
    "        ii = list_i[index]\n",
    "\n",
    "        x_hat = round((float(res[ii][1])/float(res[ii][0]))*scaler_x)\n",
    "        y_hat = round((float(res[ii][2])/float(res[ii][0]))*scaler_y)\n",
    "        r = 5\n",
    "        return x_hat,y_hat\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray,1.1,10)\n",
    "        print (eyes)\n",
    "        count  = 0 \n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "#           ex_smallest = np.minimum(ex)\n",
    "#           index_smallest = where(ex==ex_smallest)\n",
    "            count_eye = count_eye +1\n",
    "            if count_eye == 2:\n",
    "                break\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            eye_img = roi_gray[ey:ey+eh,ex:ex+ew]\n",
    "            #eye_color = roi_color[ey:ey+eh,ex:ex+ew]\n",
    "            count= count +1\n",
    "            eye_image = eye_img\n",
    "            if eye_image is not None:\n",
    "                try:\n",
    "                    x_hat,y_hat = find_iris(eye_image)\n",
    "\n",
    "                except:\n",
    "                    print ('cant find iris!')\n",
    "                else:                \n",
    "                    r = 2\n",
    "                    cv2.circle(roi_color, (np.int64(ex+x_hat), np.int64(ey+y_hat)), r, (0, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow('frame2',eye_image)\n",
    "            \n",
    "            \n",
    "    cv2.imshow('frame1',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f9c84298ccfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatrix_CV_ML3D\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mDImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtests\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMatrix_CV_ML3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_data/buffer\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_ML_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\opencv\\project_face_detection\\Matrix_CV_ML3D.py\u001b[0m in \u001b[0;36mbuild_ML_matrix\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mdot\u001b[0m           \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mclasstype\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdash\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclasstype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'image'"
     ]
    }
   ],
   "source": [
    "import Matrix_CV_ML3D as DImage\n",
    "tests = DImage.Matrix_CV_ML3D(\"train_data/buffer\",25,50)\n",
    "tests.build_ML_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "C:\\ci\\opencv_1512688052760\\work\\modules\\objdetect\\src\\cascadedetect.cpp:1698: error: (-215) !empty() in function cv::CascadeClassifier::detectMultiScale\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fce80c3ed75a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\ci\\opencv_1512688052760\\work\\modules\\objdetect\\src\\cascadedetect.cpp:1698: error: (-215) !empty() in function cv::CascadeClassifier::detectMultiScale\n"
     ]
    }
   ],
   "source": [
    "# eyeball and using ML (move it)\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import glob\n",
    "import Matrix_CV_ML3D as DImage\n",
    "#import Matrix_CV_ML_realtime as RImage\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "# haarcascade_mcs_upperbody\n",
    "model_left_eye = load_model('left_eye_model.h5')\n",
    "model_right_eye = load_model('right_eye_model.h5')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "eyecount = 0\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray,1.1,10)\n",
    "        if eyes is None:\n",
    "            pass\n",
    "        num_eyes = np.size(eyes)\n",
    "        eyecount = eyecount+1\n",
    "        num_eyes = num_eyes/4\n",
    "        if num_eyes == 1:\n",
    "            cv2.putText(frame,\"stop!\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "            \n",
    "        if num_eyes == 2:\n",
    "            # we have to find two eyes \n",
    "            count = 0\n",
    "            if eyes[0,0]<eyes[1,0]:\n",
    "                check = 1\n",
    "            else:\n",
    "                check = 2\n",
    "            for (ex,ey,ew,eh) in eyes:\n",
    "                count = count+1\n",
    "                if count == check:\n",
    "                    # left eyes\n",
    "                    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "                    eye_img = roi_gray[ey:ey+eh,ex:ex+ew]\n",
    "                    #eye_color = roi_color[ey:ey+eh,ex:ex+ew]\n",
    "                    eye_image = eye_img\n",
    "                    cv2.imshow('left eye',eye_image)\n",
    "                    resized_eyes = cv2.resize(eye_image, (50, 50))\n",
    "                    cut_image = resized_eyes[10:35,:]\n",
    "                    cut_image_expend = np.zeros((25,50,3))\n",
    "                    cut_image_expend[:,:,0] = cut_image\n",
    "                    cut_image_expend[:,:,1] = cut_image\n",
    "                    cut_image_expend[:,:,2] = cut_image\n",
    "                    img = np.reshape(cut_image_expend,(1,3,50,25))\n",
    "                    pred  = model_left_eye.predict(img)\n",
    "                    predicted = np.argmax(pred,axis=1)\n",
    "                    left_eye_result = predicted\n",
    "                else:\n",
    "                    # right eyes\n",
    "                    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "                    eye_img = roi_gray[ey:ey+eh,ex:ex+ew]\n",
    "                    #eye_color = roi_color[ey:ey+eh,ex:ex+ew]\n",
    "                    eye_image = eye_img\n",
    "                    cv2.imshow('right eye',eye_image)\n",
    "                    resized_eyes = cv2.resize(eye_image, (50, 50))\n",
    "                    cut_image = resized_eyes[10:35,:]\n",
    "                    cut_image_expend = np.zeros((25,50,3))\n",
    "                    cut_image_expend[:,:,0] = cut_image\n",
    "                    cut_image_expend[:,:,1] = cut_image\n",
    "                    cut_image_expend[:,:,2] = cut_image\n",
    "                    img = np.reshape(cut_image_expend,(1,3,50,25))\n",
    "                    pred  = model_right_eye.predict(img)\n",
    "                    predicted = np.argmax(pred,axis=1)\n",
    "                    right_eye_result = predicted\n",
    "                    \n",
    "            print (left_eye_result,right_eye_result)\n",
    "            if left_eye_result != right_eye_result:\n",
    "                    print ('move forward!')\n",
    "                    cv2.putText(frame,\"move forward!\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "            if left_eye_result == right_eye_result:\n",
    "                if left_eye_result == 0:\n",
    "                    print ('move forward!')\n",
    "                    cv2.putText(frame,\"move forward!\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "                elif left_eye_result == 1:\n",
    "                    print ('move forward!')\n",
    "                    cv2.putText(frame,\"move forward!\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "                elif left_eye_result == 2:\n",
    "                    print ('move left!')\n",
    "                    cv2.putText(frame,\"move left!\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "                elif left_eye_result == 3:\n",
    "                    print ('move right!')\n",
    "                    cv2.putText(frame,\"move right!\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "    cv2.imshow('frame1',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyeball and using number of eyes (move it)\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import glob\n",
    "import Matrix_CV_ML3D as DImage\n",
    "#import Matrix_CV_ML_realtime as RImage\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "stop\n",
      "move left!\n",
      "move left!\n",
      "move forward!\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "move right!\n",
      "move forward!\n",
      "stop\n",
      "stop\n",
      "move forward!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "stop\n",
      "stop\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "stop\n",
      "stop\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "move left!\n",
      "move forward!\n",
      "move left!\n",
      "move left!\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move right!\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move right!\n",
      "move right!\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move right!\n",
      "move left!\n",
      "move left!\n",
      "move left!\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move right!\n",
      "move right!\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "stop\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move right!\n",
      "move left!\n",
      "move right!\n",
      "move left!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "stop\n",
      "move left!\n",
      "move left!\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move right!\n",
      "move left!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "move forward!\n",
      "move right!\n",
      "move forward!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "move right!\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "move right!\n",
      "move right!\n",
      "move right!\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move forward!\n",
      "stop\n",
      "stop\n",
      "move left!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move right!\n",
      "move left!\n",
      "move forward!\n",
      "stop\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "stop\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move forward!\n",
      "move right!\n",
      "stop\n",
      "move right!\n",
      "move right!\n",
      "move forward!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "move right!\n",
      "move right!\n",
      "move right!\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "model_left_eye = load_model('left_eye_model.h5')\n",
    "model_right_eye = load_model('right_eye_model.h5')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "eyecount = 0\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if np.size(faces)==0:\n",
    "    \n",
    "        print ('stop')\n",
    "        cv2.putText(frame,\"stop\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        ##########\n",
    "        num_face = np.size(faces)\n",
    "        if np.size(faces)>1:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray,1.1,10)\n",
    "        if np.size(eyes)==0:\n",
    "            print ('stop')\n",
    "            cv2.putText(frame,\"stop\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        num_eyes = np.size(eyes)\n",
    "        eyecount = eyecount+1\n",
    "        num_eyes = num_eyes/4\n",
    "        if num_eyes == 1:\n",
    "            if eyes[0,0]<faces[0,2]/2:\n",
    "                print ('move right!')\n",
    "                cv2.putText(frame,\"move right!\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "            else:\n",
    "                print ('move left!')\n",
    "                cv2.putText(frame,\"move left!\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        if num_eyes == 2:\n",
    "            print ('move forward!')\n",
    "            cv2.putText(frame,\"move forward!\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    cv2.imshow('frame1',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# collect eyes data\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import glob\n",
    "import Matrix_CV_ML3D as DImage\n",
    "#import Matrix_CV_ML_realtime as RImage\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "model_left_eye = load_model('left_eye_model.h5')\n",
    "model_right_eye = load_model('right_eye_model.h5')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "eyecount = 0\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray,1.1,10)\n",
    "        if eyes is None:\n",
    "            pass\n",
    "        num_eyes = np.size(eyes)\n",
    "        eyecount = eyecount+1\n",
    "        num_eyes = num_eyes/4\n",
    "        if num_eyes == 2:\n",
    "            # we have to find two eyes \n",
    "            count = 0\n",
    "            if eyes[0,0]<eyes[1,0]:\n",
    "                check = 1\n",
    "            else:\n",
    "                check = 2\n",
    "            left_eye_result = 0\n",
    "            right_eye_result = 0\n",
    "            for (ex,ey,ew,eh) in eyes:\n",
    "                count = count+1\n",
    "                if count == check:\n",
    "                    # left eyes\n",
    "                    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "                    eye_img = roi_gray[ey:ey+eh,ex:ex+ew]\n",
    "                    #eye_color = roi_color[ey:ey+eh,ex:ex+ew]\n",
    "                    eye_image = eye_img\n",
    "                    cv2.imshow('left eye',eye_image)\n",
    "                    resized_eyes = cv2.resize(eye_image, (50, 50))\n",
    "                    cut_image = resized_eyes[10:35,:]\n",
    "                    dir  = \"train_data/Jinxin_left_eye/left_eye_%d.jpg\" % count\n",
    "                    cv2.imwrite(dir,cut_image)\n",
    "\n",
    "                else:\n",
    "                    # right eyes\n",
    "                    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "                    eye_img = roi_gray[ey:ey+eh,ex:ex+ew]\n",
    "                    #eye_color = roi_color[ey:ey+eh,ex:ex+ew]\n",
    "                    eye_image = eye_img\n",
    "                    cv2.imshow('right eye',eye_image)\n",
    "                    resized_eyes = cv2.resize(eye_image, (50, 50))\n",
    "                    cut_image = resized_eyes[10:35,:]\n",
    "                    dir  = \"train_data/Jinxin_right_eye/right_eye_%d.jpg\" % count\n",
    "                    cv2.imwrite(dir,cut_image)\n",
    "                \n",
    "                \n",
    "    cv2.imshow('frame1',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cut_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-407517291e46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcut_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cut_image' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img= cv2.resize(cut_image,(50,25), interpolation = cv2.INTER_CUBIC)\n",
    "img.shape\n",
    "\n",
    "cv2.imshow('figure',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda2\\envs\\OpenCV\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(3, 50, 25...)`\n",
      "C:\\anaconda2\\envs\\OpenCV\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\anaconda2\\envs\\OpenCV\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (288, 1250)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-26ebd86b37f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# 9. Fit model on training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# 10. Evaluate model on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda2\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda2\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda2\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (288, 1250)"
     ]
    }
   ],
   "source": [
    "# train the model left eye model \n",
    "# 0 look straight \n",
    "# 1 move forward\n",
    "# 2 move left \n",
    "# 3 move right \n",
    "\n",
    "# Train CNN model\n",
    "import Matrix_CV_ML3D as DImage\n",
    "import Matrix_CV_ML as NDImage\n",
    "#import Matrix_CV_ML_realtime as RImage\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "x = DImage.Matrix_CV_ML(\"train_data/Jinxin_left_eyes\",25,50)\n",
    "x.build_ML_matrix()\n",
    "\n",
    "labels = np.zeros(288)\n",
    "labels[0:20] = 0\n",
    "labels[21:57] = 1\n",
    "labels[58:58+110] = 2\n",
    "labels[169:287] = 3\n",
    "x.labels = labels\n",
    "y = np_utils.to_categorical(x.labels)\n",
    "x = x.global_matrix\n",
    "x = x.astype('float32')/255 # wrong! should choose max in image \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(3,50,25)))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "   \n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    " \n",
    "# 8. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 9. Fit model on training data\n",
    "model.fit(x, y, batch_size=32, nb_epoch=80,  shuffle = True, verbose=2)\n",
    " \n",
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(x, y, verbose=0)\n",
    "\n",
    "# Save Training Model\n",
    "\n",
    "model.save('left_eye_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 50, 25)(1, 3, 50, 25)\n",
      "(1, 3, 50, 25)(2, 3, 50, 25)\n",
      "(1, 3, 50, 25)(3, 3, 50, 25)\n",
      "(1, 3, 50, 25)(4, 3, 50, 25)\n",
      "(1, 3, 50, 25)(5, 3, 50, 25)\n",
      "(1, 3, 50, 25)(6, 3, 50, 25)\n",
      "(1, 3, 50, 25)(7, 3, 50, 25)\n",
      "(1, 3, 50, 25)(8, 3, 50, 25)\n",
      "(1, 3, 50, 25)(9, 3, 50, 25)\n",
      "(1, 3, 50, 25)(10, 3, 50, 25)\n",
      "(1, 3, 50, 25)(11, 3, 50, 25)\n",
      "(1, 3, 50, 25)(12, 3, 50, 25)\n",
      "(1, 3, 50, 25)(13, 3, 50, 25)\n",
      "(1, 3, 50, 25)(14, 3, 50, 25)\n",
      "(1, 3, 50, 25)(15, 3, 50, 25)\n",
      "(1, 3, 50, 25)(16, 3, 50, 25)\n",
      "(1, 3, 50, 25)(17, 3, 50, 25)\n",
      "(1, 3, 50, 25)(18, 3, 50, 25)\n",
      "(1, 3, 50, 25)(19, 3, 50, 25)\n",
      "(1, 3, 50, 25)(20, 3, 50, 25)\n",
      "(1, 3, 50, 25)(21, 3, 50, 25)\n",
      "(1, 3, 50, 25)(22, 3, 50, 25)\n",
      "[0 0 0 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test left eye CNN model\n",
    "import Matrix_CV_ML3D as DImage\n",
    "#import Matrix_CV_ML_realtime as RImage\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "test = DImage.Matrix_CV_ML3D(\"test_data/Jinxin_left_eyes_test\",25,50)\n",
    "test.build_ML_matrix()\n",
    "test = test.global_matrix\n",
    "test = test.astype('float32')/255\n",
    "model = load_model('left_eye_model.h5')\n",
    "pred  = model.predict(test)\n",
    "predicted = np.argmax(pred,axis=1)\n",
    "print (predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 50, 25)(1, 3, 50, 25)\n",
      "(1, 3, 50, 25)(2, 3, 50, 25)\n",
      "(1, 3, 50, 25)(3, 3, 50, 25)\n",
      "(1, 3, 50, 25)(4, 3, 50, 25)\n",
      "(1, 3, 50, 25)(5, 3, 50, 25)\n",
      "(1, 3, 50, 25)(6, 3, 50, 25)\n",
      "(1, 3, 50, 25)(7, 3, 50, 25)\n",
      "(1, 3, 50, 25)(8, 3, 50, 25)\n",
      "(1, 3, 50, 25)(9, 3, 50, 25)\n",
      "(1, 3, 50, 25)(10, 3, 50, 25)\n",
      "(1, 3, 50, 25)(11, 3, 50, 25)\n",
      "(1, 3, 50, 25)(12, 3, 50, 25)\n",
      "(1, 3, 50, 25)(13, 3, 50, 25)\n",
      "(1, 3, 50, 25)(14, 3, 50, 25)\n",
      "(1, 3, 50, 25)(15, 3, 50, 25)\n",
      "(1, 3, 50, 25)(16, 3, 50, 25)\n",
      "(1, 3, 50, 25)(17, 3, 50, 25)\n",
      "(1, 3, 50, 25)(18, 3, 50, 25)\n",
      "(1, 3, 50, 25)(19, 3, 50, 25)\n",
      "(1, 3, 50, 25)(20, 3, 50, 25)\n",
      "(1, 3, 50, 25)(21, 3, 50, 25)\n",
      "(1, 3, 50, 25)(22, 3, 50, 25)\n",
      "(1, 3, 50, 25)(23, 3, 50, 25)\n",
      "(1, 3, 50, 25)(24, 3, 50, 25)\n",
      "(1, 3, 50, 25)(25, 3, 50, 25)\n",
      "(1, 3, 50, 25)(26, 3, 50, 25)\n",
      "(1, 3, 50, 25)(27, 3, 50, 25)\n",
      "(1, 3, 50, 25)(28, 3, 50, 25)\n",
      "(1, 3, 50, 25)(29, 3, 50, 25)\n",
      "(1, 3, 50, 25)(30, 3, 50, 25)\n",
      "(1, 3, 50, 25)(31, 3, 50, 25)\n",
      "(1, 3, 50, 25)(32, 3, 50, 25)\n",
      "(1, 3, 50, 25)(33, 3, 50, 25)\n",
      "(1, 3, 50, 25)(34, 3, 50, 25)\n",
      "(1, 3, 50, 25)(35, 3, 50, 25)\n",
      "(1, 3, 50, 25)(36, 3, 50, 25)\n",
      "(1, 3, 50, 25)(37, 3, 50, 25)\n",
      "(1, 3, 50, 25)(38, 3, 50, 25)\n",
      "(1, 3, 50, 25)(39, 3, 50, 25)\n",
      "(1, 3, 50, 25)(40, 3, 50, 25)\n",
      "(1, 3, 50, 25)(41, 3, 50, 25)\n",
      "(1, 3, 50, 25)(42, 3, 50, 25)\n",
      "(1, 3, 50, 25)(43, 3, 50, 25)\n",
      "(1, 3, 50, 25)(44, 3, 50, 25)\n",
      "(1, 3, 50, 25)(45, 3, 50, 25)\n",
      "(1, 3, 50, 25)(46, 3, 50, 25)\n",
      "(1, 3, 50, 25)(47, 3, 50, 25)\n",
      "(1, 3, 50, 25)(48, 3, 50, 25)\n",
      "(1, 3, 50, 25)(49, 3, 50, 25)\n",
      "(1, 3, 50, 25)(50, 3, 50, 25)\n",
      "(1, 3, 50, 25)(51, 3, 50, 25)\n",
      "(1, 3, 50, 25)(52, 3, 50, 25)\n",
      "(1, 3, 50, 25)(53, 3, 50, 25)\n",
      "(1, 3, 50, 25)(54, 3, 50, 25)\n",
      "(1, 3, 50, 25)(55, 3, 50, 25)\n",
      "(1, 3, 50, 25)(56, 3, 50, 25)\n",
      "(1, 3, 50, 25)(57, 3, 50, 25)\n",
      "(1, 3, 50, 25)(58, 3, 50, 25)\n",
      "(1, 3, 50, 25)(59, 3, 50, 25)\n",
      "(1, 3, 50, 25)(60, 3, 50, 25)\n",
      "(1, 3, 50, 25)(61, 3, 50, 25)\n",
      "(1, 3, 50, 25)(62, 3, 50, 25)\n",
      "(1, 3, 50, 25)(63, 3, 50, 25)\n",
      "(1, 3, 50, 25)(64, 3, 50, 25)\n",
      "(1, 3, 50, 25)(65, 3, 50, 25)\n",
      "(1, 3, 50, 25)(66, 3, 50, 25)\n",
      "(1, 3, 50, 25)(67, 3, 50, 25)\n",
      "(1, 3, 50, 25)(68, 3, 50, 25)\n",
      "(1, 3, 50, 25)(69, 3, 50, 25)\n",
      "(1, 3, 50, 25)(70, 3, 50, 25)\n",
      "(1, 3, 50, 25)(71, 3, 50, 25)\n",
      "(1, 3, 50, 25)(72, 3, 50, 25)\n",
      "(1, 3, 50, 25)(73, 3, 50, 25)\n",
      "(1, 3, 50, 25)(74, 3, 50, 25)\n",
      "(1, 3, 50, 25)(75, 3, 50, 25)\n",
      "(1, 3, 50, 25)(76, 3, 50, 25)\n",
      "(1, 3, 50, 25)(77, 3, 50, 25)\n",
      "(1, 3, 50, 25)(78, 3, 50, 25)\n",
      "(1, 3, 50, 25)(79, 3, 50, 25)\n",
      "(1, 3, 50, 25)(80, 3, 50, 25)\n",
      "(1, 3, 50, 25)(81, 3, 50, 25)\n",
      "(1, 3, 50, 25)(82, 3, 50, 25)\n",
      "(1, 3, 50, 25)(83, 3, 50, 25)\n",
      "(1, 3, 50, 25)(84, 3, 50, 25)\n",
      "(1, 3, 50, 25)(85, 3, 50, 25)\n",
      "(1, 3, 50, 25)(86, 3, 50, 25)\n",
      "(1, 3, 50, 25)(87, 3, 50, 25)\n",
      "(1, 3, 50, 25)(88, 3, 50, 25)\n",
      "(1, 3, 50, 25)(89, 3, 50, 25)\n",
      "(1, 3, 50, 25)(90, 3, 50, 25)\n",
      "(1, 3, 50, 25)(91, 3, 50, 25)\n",
      "(1, 3, 50, 25)(92, 3, 50, 25)\n",
      "(1, 3, 50, 25)(93, 3, 50, 25)\n",
      "(1, 3, 50, 25)(94, 3, 50, 25)\n",
      "(1, 3, 50, 25)(95, 3, 50, 25)\n",
      "(1, 3, 50, 25)(96, 3, 50, 25)\n",
      "(1, 3, 50, 25)(97, 3, 50, 25)\n",
      "(1, 3, 50, 25)(98, 3, 50, 25)\n",
      "(1, 3, 50, 25)(99, 3, 50, 25)\n",
      "(1, 3, 50, 25)(100, 3, 50, 25)\n",
      "(1, 3, 50, 25)(101, 3, 50, 25)\n",
      "(1, 3, 50, 25)(102, 3, 50, 25)\n",
      "(1, 3, 50, 25)(103, 3, 50, 25)\n",
      "(1, 3, 50, 25)(104, 3, 50, 25)\n",
      "(1, 3, 50, 25)(105, 3, 50, 25)\n",
      "(1, 3, 50, 25)(106, 3, 50, 25)\n",
      "(1, 3, 50, 25)(107, 3, 50, 25)\n",
      "(1, 3, 50, 25)(108, 3, 50, 25)\n",
      "(1, 3, 50, 25)(109, 3, 50, 25)\n",
      "(1, 3, 50, 25)(110, 3, 50, 25)\n",
      "(1, 3, 50, 25)(111, 3, 50, 25)\n",
      "(1, 3, 50, 25)(112, 3, 50, 25)\n",
      "(1, 3, 50, 25)(113, 3, 50, 25)\n",
      "(1, 3, 50, 25)(114, 3, 50, 25)\n",
      "(1, 3, 50, 25)(115, 3, 50, 25)\n",
      "(1, 3, 50, 25)(116, 3, 50, 25)\n",
      "(1, 3, 50, 25)(117, 3, 50, 25)\n",
      "(1, 3, 50, 25)(118, 3, 50, 25)\n",
      "(1, 3, 50, 25)(119, 3, 50, 25)\n",
      "(1, 3, 50, 25)(120, 3, 50, 25)\n",
      "(1, 3, 50, 25)(121, 3, 50, 25)\n",
      "(1, 3, 50, 25)(122, 3, 50, 25)\n",
      "(1, 3, 50, 25)(123, 3, 50, 25)\n",
      "(1, 3, 50, 25)(124, 3, 50, 25)\n",
      "(1, 3, 50, 25)(125, 3, 50, 25)\n",
      "(1, 3, 50, 25)(126, 3, 50, 25)\n",
      "(1, 3, 50, 25)(127, 3, 50, 25)\n",
      "(1, 3, 50, 25)(128, 3, 50, 25)\n",
      "(1, 3, 50, 25)(129, 3, 50, 25)\n",
      "(1, 3, 50, 25)(130, 3, 50, 25)\n",
      "(1, 3, 50, 25)(131, 3, 50, 25)\n",
      "(1, 3, 50, 25)(132, 3, 50, 25)\n",
      "(1, 3, 50, 25)(133, 3, 50, 25)\n",
      "(1, 3, 50, 25)(134, 3, 50, 25)\n",
      "(1, 3, 50, 25)(135, 3, 50, 25)\n",
      "(1, 3, 50, 25)(136, 3, 50, 25)\n",
      "(1, 3, 50, 25)(137, 3, 50, 25)\n",
      "(1, 3, 50, 25)(138, 3, 50, 25)\n",
      "(1, 3, 50, 25)(139, 3, 50, 25)\n",
      "(1, 3, 50, 25)(140, 3, 50, 25)\n",
      "(1, 3, 50, 25)(141, 3, 50, 25)\n",
      "(1, 3, 50, 25)(142, 3, 50, 25)\n",
      "(1, 3, 50, 25)(143, 3, 50, 25)\n",
      "(1, 3, 50, 25)(144, 3, 50, 25)\n",
      "(1, 3, 50, 25)(145, 3, 50, 25)\n",
      "(1, 3, 50, 25)(146, 3, 50, 25)\n",
      "(1, 3, 50, 25)(147, 3, 50, 25)\n",
      "(1, 3, 50, 25)(148, 3, 50, 25)\n",
      "(1, 3, 50, 25)(149, 3, 50, 25)\n",
      "(1, 3, 50, 25)(150, 3, 50, 25)\n",
      "(1, 3, 50, 25)(151, 3, 50, 25)\n",
      "(1, 3, 50, 25)(152, 3, 50, 25)\n",
      "(1, 3, 50, 25)(153, 3, 50, 25)\n",
      "(1, 3, 50, 25)(154, 3, 50, 25)\n",
      "(1, 3, 50, 25)(155, 3, 50, 25)\n",
      "(1, 3, 50, 25)(156, 3, 50, 25)\n",
      "(1, 3, 50, 25)(157, 3, 50, 25)\n",
      "(1, 3, 50, 25)(158, 3, 50, 25)\n",
      "(1, 3, 50, 25)(159, 3, 50, 25)\n",
      "(1, 3, 50, 25)(160, 3, 50, 25)\n",
      "(1, 3, 50, 25)(161, 3, 50, 25)\n",
      "(1, 3, 50, 25)(162, 3, 50, 25)\n",
      "(1, 3, 50, 25)(163, 3, 50, 25)\n",
      "(1, 3, 50, 25)(164, 3, 50, 25)\n",
      "(1, 3, 50, 25)(165, 3, 50, 25)\n",
      "(1, 3, 50, 25)(166, 3, 50, 25)\n",
      "(1, 3, 50, 25)(167, 3, 50, 25)\n",
      "(1, 3, 50, 25)(168, 3, 50, 25)\n",
      "(1, 3, 50, 25)(169, 3, 50, 25)\n",
      "(1, 3, 50, 25)(170, 3, 50, 25)\n",
      "(1, 3, 50, 25)(171, 3, 50, 25)\n",
      "(1, 3, 50, 25)(172, 3, 50, 25)\n",
      "(1, 3, 50, 25)(173, 3, 50, 25)\n",
      "(1, 3, 50, 25)(174, 3, 50, 25)\n",
      "(1, 3, 50, 25)(175, 3, 50, 25)\n",
      "(1, 3, 50, 25)(176, 3, 50, 25)\n",
      "(1, 3, 50, 25)(177, 3, 50, 25)\n",
      "(1, 3, 50, 25)(178, 3, 50, 25)\n",
      "(1, 3, 50, 25)(179, 3, 50, 25)\n",
      "(1, 3, 50, 25)(180, 3, 50, 25)\n",
      "(1, 3, 50, 25)(181, 3, 50, 25)\n",
      "(1, 3, 50, 25)(182, 3, 50, 25)\n",
      "(1, 3, 50, 25)(183, 3, 50, 25)\n",
      "(1, 3, 50, 25)(184, 3, 50, 25)\n",
      "(1, 3, 50, 25)(185, 3, 50, 25)\n",
      "(1, 3, 50, 25)(186, 3, 50, 25)\n",
      "(1, 3, 50, 25)(187, 3, 50, 25)\n",
      "(1, 3, 50, 25)(188, 3, 50, 25)\n",
      "(1, 3, 50, 25)(189, 3, 50, 25)\n",
      "(1, 3, 50, 25)(190, 3, 50, 25)\n",
      "(1, 3, 50, 25)(191, 3, 50, 25)\n",
      "(1, 3, 50, 25)(192, 3, 50, 25)\n",
      "(1, 3, 50, 25)(193, 3, 50, 25)\n",
      "(1, 3, 50, 25)(194, 3, 50, 25)\n",
      "(1, 3, 50, 25)(195, 3, 50, 25)\n",
      "(1, 3, 50, 25)(196, 3, 50, 25)\n",
      "(1, 3, 50, 25)(197, 3, 50, 25)\n",
      "(1, 3, 50, 25)(198, 3, 50, 25)\n",
      "(1, 3, 50, 25)(199, 3, 50, 25)\n",
      "(1, 3, 50, 25)(200, 3, 50, 25)\n",
      "(1, 3, 50, 25)(201, 3, 50, 25)\n",
      "(1, 3, 50, 25)(202, 3, 50, 25)\n",
      "(1, 3, 50, 25)(203, 3, 50, 25)\n",
      "(1, 3, 50, 25)(204, 3, 50, 25)\n",
      "(1, 3, 50, 25)(205, 3, 50, 25)\n",
      "(1, 3, 50, 25)(206, 3, 50, 25)\n",
      "(1, 3, 50, 25)(207, 3, 50, 25)\n",
      "(1, 3, 50, 25)(208, 3, 50, 25)\n",
      "(1, 3, 50, 25)(209, 3, 50, 25)\n",
      "(1, 3, 50, 25)(210, 3, 50, 25)\n",
      "(1, 3, 50, 25)(211, 3, 50, 25)\n",
      "(1, 3, 50, 25)(212, 3, 50, 25)\n",
      "(1, 3, 50, 25)(213, 3, 50, 25)\n",
      "(1, 3, 50, 25)(214, 3, 50, 25)\n",
      "(1, 3, 50, 25)(215, 3, 50, 25)\n",
      "(1, 3, 50, 25)(216, 3, 50, 25)\n",
      "(1, 3, 50, 25)(217, 3, 50, 25)\n",
      "(1, 3, 50, 25)(218, 3, 50, 25)\n",
      "(1, 3, 50, 25)(219, 3, 50, 25)\n",
      "(1, 3, 50, 25)(220, 3, 50, 25)\n",
      "(1, 3, 50, 25)(221, 3, 50, 25)\n",
      "(1, 3, 50, 25)(222, 3, 50, 25)\n",
      "(1, 3, 50, 25)(223, 3, 50, 25)\n",
      "(1, 3, 50, 25)(224, 3, 50, 25)\n",
      "(1, 3, 50, 25)(225, 3, 50, 25)\n",
      "(1, 3, 50, 25)(226, 3, 50, 25)\n",
      "(1, 3, 50, 25)(227, 3, 50, 25)\n",
      "(1, 3, 50, 25)(228, 3, 50, 25)\n",
      "(1, 3, 50, 25)(229, 3, 50, 25)\n",
      "(1, 3, 50, 25)(230, 3, 50, 25)\n",
      "(1, 3, 50, 25)(231, 3, 50, 25)\n",
      "(1, 3, 50, 25)(232, 3, 50, 25)\n",
      "(1, 3, 50, 25)(233, 3, 50, 25)\n",
      "(1, 3, 50, 25)(234, 3, 50, 25)\n",
      "(1, 3, 50, 25)(235, 3, 50, 25)\n",
      "(1, 3, 50, 25)(236, 3, 50, 25)\n",
      "(1, 3, 50, 25)(237, 3, 50, 25)\n",
      "(1, 3, 50, 25)(238, 3, 50, 25)\n",
      "(1, 3, 50, 25)(239, 3, 50, 25)\n",
      "(1, 3, 50, 25)(240, 3, 50, 25)\n",
      "(1, 3, 50, 25)(241, 3, 50, 25)\n",
      "(1, 3, 50, 25)(242, 3, 50, 25)\n",
      "(1, 3, 50, 25)(243, 3, 50, 25)\n",
      "(1, 3, 50, 25)(244, 3, 50, 25)\n",
      "(1, 3, 50, 25)(245, 3, 50, 25)\n",
      "(1, 3, 50, 25)(246, 3, 50, 25)\n",
      "(1, 3, 50, 25)(247, 3, 50, 25)\n",
      "(1, 3, 50, 25)(248, 3, 50, 25)\n",
      "(1, 3, 50, 25)(249, 3, 50, 25)\n",
      "(1, 3, 50, 25)(250, 3, 50, 25)\n",
      "(1, 3, 50, 25)(251, 3, 50, 25)\n",
      "(1, 3, 50, 25)(252, 3, 50, 25)\n",
      "(1, 3, 50, 25)(253, 3, 50, 25)\n",
      "(1, 3, 50, 25)(254, 3, 50, 25)\n",
      "(1, 3, 50, 25)(255, 3, 50, 25)\n",
      "(1, 3, 50, 25)(256, 3, 50, 25)\n",
      "(1, 3, 50, 25)(257, 3, 50, 25)\n",
      "(1, 3, 50, 25)(258, 3, 50, 25)\n",
      "(1, 3, 50, 25)(259, 3, 50, 25)\n",
      "(1, 3, 50, 25)(260, 3, 50, 25)\n",
      "(1, 3, 50, 25)(261, 3, 50, 25)\n",
      "(1, 3, 50, 25)(262, 3, 50, 25)\n",
      "(1, 3, 50, 25)(263, 3, 50, 25)\n",
      "(1, 3, 50, 25)(264, 3, 50, 25)\n",
      "(1, 3, 50, 25)(265, 3, 50, 25)\n",
      "(1, 3, 50, 25)(266, 3, 50, 25)\n",
      "(1, 3, 50, 25)(267, 3, 50, 25)\n",
      "(1, 3, 50, 25)(268, 3, 50, 25)\n",
      "(1, 3, 50, 25)(269, 3, 50, 25)\n",
      "(1, 3, 50, 25)(270, 3, 50, 25)\n",
      "(1, 3, 50, 25)(271, 3, 50, 25)\n",
      "(1, 3, 50, 25)(272, 3, 50, 25)\n",
      "(1, 3, 50, 25)(273, 3, 50, 25)\n",
      "(1, 3, 50, 25)(274, 3, 50, 25)\n",
      "(1, 3, 50, 25)(275, 3, 50, 25)\n",
      "(1, 3, 50, 25)(276, 3, 50, 25)\n",
      "(1, 3, 50, 25)(277, 3, 50, 25)\n",
      "(1, 3, 50, 25)(278, 3, 50, 25)\n",
      "(1, 3, 50, 25)(279, 3, 50, 25)\n",
      "(1, 3, 50, 25)(280, 3, 50, 25)\n",
      "(1, 3, 50, 25)(281, 3, 50, 25)\n",
      "(1, 3, 50, 25)(282, 3, 50, 25)\n",
      "(1, 3, 50, 25)(283, 3, 50, 25)\n",
      "(1, 3, 50, 25)(284, 3, 50, 25)\n",
      "(1, 3, 50, 25)(285, 3, 50, 25)\n",
      "(1, 3, 50, 25)(286, 3, 50, 25)\n",
      "(1, 3, 50, 25)(287, 3, 50, 25)\n",
      "(1, 3, 50, 25)(288, 3, 50, 25)\n",
      "(1, 3, 50, 25)(289, 3, 50, 25)\n",
      "(1, 3, 50, 25)(290, 3, 50, 25)\n",
      "(1, 3, 50, 25)(291, 3, 50, 25)\n",
      "(1, 3, 50, 25)(292, 3, 50, 25)\n",
      "(1, 3, 50, 25)(293, 3, 50, 25)\n",
      "(1, 3, 50, 25)(294, 3, 50, 25)\n",
      "(1, 3, 50, 25)(295, 3, 50, 25)\n",
      "(1, 3, 50, 25)(296, 3, 50, 25)\n",
      "(1, 3, 50, 25)(297, 3, 50, 25)\n",
      "(1, 3, 50, 25)(298, 3, 50, 25)\n",
      "(1, 3, 50, 25)(299, 3, 50, 25)\n",
      "(1, 3, 50, 25)(300, 3, 50, 25)\n",
      "(1, 3, 50, 25)(301, 3, 50, 25)\n",
      "(1, 3, 50, 25)(302, 3, 50, 25)\n",
      "(1, 3, 50, 25)(303, 3, 50, 25)\n",
      "(1, 3, 50, 25)(304, 3, 50, 25)\n",
      "(1, 3, 50, 25)(305, 3, 50, 25)\n",
      "(1, 3, 50, 25)(306, 3, 50, 25)\n",
      "(1, 3, 50, 25)(307, 3, 50, 25)\n",
      "(1, 3, 50, 25)(308, 3, 50, 25)\n",
      "(1, 3, 50, 25)(309, 3, 50, 25)\n",
      "(1, 3, 50, 25)(310, 3, 50, 25)\n",
      "(1, 3, 50, 25)(311, 3, 50, 25)\n",
      "(1, 3, 50, 25)(312, 3, 50, 25)\n",
      "(1, 3, 50, 25)(313, 3, 50, 25)\n",
      "(1, 3, 50, 25)(314, 3, 50, 25)\n",
      "(1, 3, 50, 25)(315, 3, 50, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda2\\envs\\OpenCV\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(3, 50, 25...)`\n",
      "C:\\anaconda2\\envs\\OpenCV\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\anaconda2\\envs\\OpenCV\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      " - 4s - loss: 1.3564 - acc: 0.3892\n",
      "Epoch 2/80\n",
      " - 3s - loss: 1.1431 - acc: 0.4430\n",
      "Epoch 3/80\n",
      " - 3s - loss: 1.0195 - acc: 0.5063\n",
      "Epoch 4/80\n",
      " - 3s - loss: 0.9061 - acc: 0.6171\n",
      "Epoch 5/80\n",
      " - 3s - loss: 0.7665 - acc: 0.7184\n",
      "Epoch 6/80\n",
      " - 3s - loss: 0.7287 - acc: 0.6835\n",
      "Epoch 7/80\n",
      " - 3s - loss: 0.6592 - acc: 0.7057\n",
      "Epoch 8/80\n",
      " - 3s - loss: 0.5961 - acc: 0.7595\n",
      "Epoch 9/80\n",
      " - 3s - loss: 0.5920 - acc: 0.7468\n",
      "Epoch 10/80\n",
      " - 3s - loss: 0.5565 - acc: 0.7563\n",
      "Epoch 11/80\n",
      " - 3s - loss: 0.5336 - acc: 0.7848\n",
      "Epoch 12/80\n",
      " - 3s - loss: 0.5312 - acc: 0.7595\n",
      "Epoch 13/80\n",
      " - 3s - loss: 0.5263 - acc: 0.7816\n",
      "Epoch 14/80\n",
      " - 3s - loss: 0.4912 - acc: 0.8070\n",
      "Epoch 15/80\n",
      " - 3s - loss: 0.4824 - acc: 0.7816\n",
      "Epoch 16/80\n",
      " - 3s - loss: 0.4946 - acc: 0.7848\n",
      "Epoch 17/80\n",
      " - 3s - loss: 0.4946 - acc: 0.8070\n",
      "Epoch 18/80\n",
      " - 3s - loss: 0.4702 - acc: 0.8101\n",
      "Epoch 19/80\n",
      " - 3s - loss: 0.4698 - acc: 0.8070\n",
      "Epoch 20/80\n",
      " - 3s - loss: 0.4547 - acc: 0.8259\n",
      "Epoch 21/80\n",
      " - 3s - loss: 0.4475 - acc: 0.8070\n",
      "Epoch 22/80\n",
      " - 3s - loss: 0.4385 - acc: 0.8228\n",
      "Epoch 23/80\n",
      " - 3s - loss: 0.4117 - acc: 0.8449\n",
      "Epoch 24/80\n",
      " - 3s - loss: 0.4213 - acc: 0.8133\n",
      "Epoch 25/80\n",
      " - 3s - loss: 0.4076 - acc: 0.8291\n",
      "Epoch 26/80\n",
      " - 3s - loss: 0.3969 - acc: 0.8544\n",
      "Epoch 27/80\n",
      " - 3s - loss: 0.4046 - acc: 0.8418\n",
      "Epoch 28/80\n",
      " - 3s - loss: 0.3804 - acc: 0.8703\n",
      "Epoch 29/80\n",
      " - 3s - loss: 0.3668 - acc: 0.8544\n",
      "Epoch 30/80\n",
      " - 3s - loss: 0.3920 - acc: 0.8418\n",
      "Epoch 31/80\n",
      " - 3s - loss: 0.3588 - acc: 0.8323\n",
      "Epoch 32/80\n",
      " - 3s - loss: 0.3433 - acc: 0.8608\n",
      "Epoch 33/80\n",
      " - 3s - loss: 0.3346 - acc: 0.8671\n",
      "Epoch 34/80\n",
      " - 3s - loss: 0.3263 - acc: 0.8892\n",
      "Epoch 35/80\n",
      " - 3s - loss: 0.3387 - acc: 0.8671\n",
      "Epoch 36/80\n",
      " - 3s - loss: 0.3469 - acc: 0.8608\n",
      "Epoch 37/80\n",
      " - 3s - loss: 0.3460 - acc: 0.8829\n",
      "Epoch 38/80\n",
      " - 3s - loss: 0.3107 - acc: 0.8797\n",
      "Epoch 39/80\n",
      " - 4s - loss: 0.3108 - acc: 0.8608\n",
      "Epoch 40/80\n",
      " - 4s - loss: 0.2928 - acc: 0.9019\n",
      "Epoch 41/80\n",
      " - 4s - loss: 0.2697 - acc: 0.9019\n",
      "Epoch 42/80\n",
      " - 4s - loss: 0.2664 - acc: 0.9114\n",
      "Epoch 43/80\n",
      " - 3s - loss: 0.2777 - acc: 0.8987\n",
      "Epoch 44/80\n",
      " - 3s - loss: 0.2953 - acc: 0.8892\n",
      "Epoch 45/80\n",
      " - 3s - loss: 0.2812 - acc: 0.8861\n",
      "Epoch 46/80\n",
      " - 3s - loss: 0.2465 - acc: 0.9051\n",
      "Epoch 47/80\n",
      " - 3s - loss: 0.2352 - acc: 0.9209\n",
      "Epoch 48/80\n",
      " - 3s - loss: 0.2424 - acc: 0.9241\n",
      "Epoch 49/80\n",
      " - 3s - loss: 0.2170 - acc: 0.9114\n",
      "Epoch 50/80\n",
      " - 3s - loss: 0.1970 - acc: 0.9399\n",
      "Epoch 51/80\n",
      " - 4s - loss: 0.1981 - acc: 0.9241\n",
      "Epoch 52/80\n",
      " - 3s - loss: 0.2119 - acc: 0.9241\n",
      "Epoch 53/80\n",
      " - 4s - loss: 0.2002 - acc: 0.9272\n",
      "Epoch 54/80\n",
      " - 4s - loss: 0.2269 - acc: 0.9209\n",
      "Epoch 55/80\n",
      " - 4s - loss: 0.2187 - acc: 0.9177\n",
      "Epoch 56/80\n",
      " - 3s - loss: 0.1898 - acc: 0.9177\n",
      "Epoch 57/80\n",
      " - 4s - loss: 0.1852 - acc: 0.9430\n",
      "Epoch 58/80\n",
      " - 4s - loss: 0.2061 - acc: 0.9177\n",
      "Epoch 59/80\n",
      " - 3s - loss: 0.2026 - acc: 0.9272\n",
      "Epoch 60/80\n",
      " - 3s - loss: 0.1903 - acc: 0.9272\n",
      "Epoch 61/80\n",
      " - 3s - loss: 0.1853 - acc: 0.9304\n",
      "Epoch 62/80\n",
      " - 4s - loss: 0.1874 - acc: 0.9209\n",
      "Epoch 63/80\n",
      " - 3s - loss: 0.1699 - acc: 0.9335\n",
      "Epoch 64/80\n",
      " - 3s - loss: 0.1574 - acc: 0.9494\n",
      "Epoch 65/80\n",
      " - 3s - loss: 0.1552 - acc: 0.9494\n",
      "Epoch 66/80\n",
      " - 3s - loss: 0.1362 - acc: 0.9620\n",
      "Epoch 67/80\n",
      " - 4s - loss: 0.1702 - acc: 0.9304\n",
      "Epoch 68/80\n",
      " - 3s - loss: 0.1721 - acc: 0.9462\n",
      "Epoch 69/80\n",
      " - 3s - loss: 0.1571 - acc: 0.9367\n",
      "Epoch 70/80\n",
      " - 4s - loss: 0.1478 - acc: 0.9399\n",
      "Epoch 71/80\n",
      " - 4s - loss: 0.1278 - acc: 0.9525\n",
      "Epoch 72/80\n",
      " - 4s - loss: 0.1330 - acc: 0.9525\n",
      "Epoch 73/80\n",
      " - 4s - loss: 0.1415 - acc: 0.9494\n",
      "Epoch 74/80\n",
      " - 3s - loss: 0.1819 - acc: 0.9272\n",
      "Epoch 75/80\n",
      " - 3s - loss: 0.1701 - acc: 0.9146\n",
      "Epoch 76/80\n",
      " - 4s - loss: 0.1551 - acc: 0.9525\n",
      "Epoch 77/80\n",
      " - 3s - loss: 0.1583 - acc: 0.9430\n",
      "Epoch 78/80\n",
      " - 3s - loss: 0.1365 - acc: 0.9525\n",
      "Epoch 79/80\n",
      " - 4s - loss: 0.1346 - acc: 0.9557\n",
      "Epoch 80/80\n",
      " - 3s - loss: 0.1009 - acc: 0.9589\n"
     ]
    }
   ],
   "source": [
    "# train the model right eye model \n",
    "# 0 look straight \n",
    "# 1 move forward\n",
    "# 2 move left \n",
    "# 3 move right \n",
    "\n",
    "# Train CNN model\n",
    "import Matrix_CV_ML3D as DImage\n",
    "#import Matrix_CV_ML_realtime as RImage\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "x = DImage.Matrix_CV_ML3D(\"train_data/Jinxin_right_eyes\",25,50)\n",
    "x.build_ML_matrix()\n",
    "\n",
    "labels = np.zeros(316)\n",
    "labels[0:23] = 0\n",
    "labels[24:60] = 1\n",
    "labels[61:61+110] = 2\n",
    "labels[172:315] = 3\n",
    "x.labels = labels\n",
    "y = np_utils.to_categorical(x.labels)\n",
    "x = x.global_matrix\n",
    "x = x.astype('float32')/255\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(3,50,25)))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "   \n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    " \n",
    "# 8. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 9. Fit model on training data\n",
    "model.fit(x, y, batch_size=32, nb_epoch=80,  shuffle = True, verbose=2)\n",
    "\n",
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(x, y, verbose=0)\n",
    "\n",
    "# Save Training Model\n",
    "\n",
    "model.save('right_eye_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 50, 25)(1, 3, 50, 25)\n",
      "(1, 3, 50, 25)(2, 3, 50, 25)\n",
      "(1, 3, 50, 25)(3, 3, 50, 25)\n",
      "(1, 3, 50, 25)(4, 3, 50, 25)\n",
      "(1, 3, 50, 25)(5, 3, 50, 25)\n",
      "(1, 3, 50, 25)(6, 3, 50, 25)\n",
      "(1, 3, 50, 25)(7, 3, 50, 25)\n",
      "(1, 3, 50, 25)(8, 3, 50, 25)\n",
      "(1, 3, 50, 25)(9, 3, 50, 25)\n",
      "(1, 3, 50, 25)(10, 3, 50, 25)\n",
      "(1, 3, 50, 25)(11, 3, 50, 25)\n",
      "(1, 3, 50, 25)(12, 3, 50, 25)\n",
      "(1, 3, 50, 25)(13, 3, 50, 25)\n",
      "(1, 3, 50, 25)(14, 3, 50, 25)\n",
      "(1, 3, 50, 25)(15, 3, 50, 25)\n",
      "(1, 3, 50, 25)(16, 3, 50, 25)\n",
      "(1, 3, 50, 25)(17, 3, 50, 25)\n",
      "(1, 3, 50, 25)(18, 3, 50, 25)\n",
      "(1, 3, 50, 25)(19, 3, 50, 25)\n",
      "(1, 3, 50, 25)(20, 3, 50, 25)\n",
      "(1, 3, 50, 25)(21, 3, 50, 25)\n",
      "(1, 3, 50, 25)(22, 3, 50, 25)\n",
      "(1, 3, 50, 25)(23, 3, 50, 25)\n",
      "(1, 3, 50, 25)(24, 3, 50, 25)\n",
      "(1, 3, 50, 25)(25, 3, 50, 25)\n",
      "[0 0 0 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 2 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Test left eye CNN model\n",
    "import Matrix_CV_ML3D as DImage\n",
    "#import Matrix_CV_ML_realtime as RImage\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "test = DImage.Matrix_CV_ML3D(\"test_data/Jinxin_right_eyes_test\",25,50)\n",
    "test.build_ML_matrix()\n",
    "test = test.global_matrix\n",
    "test = test.astype('float32')/255\n",
    "model = load_model('right_eye_model.h5')\n",
    "pred  = model.predict(test)\n",
    "predicted = np.argmax(pred,axis=1)\n",
    "print (predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
